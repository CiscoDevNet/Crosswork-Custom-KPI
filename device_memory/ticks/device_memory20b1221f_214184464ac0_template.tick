//-----------------------------------------------------------------------------
// {{ script_id.value }} - Pulse TICKscript Template
//
// Master template: two_level_threshold-master-template
//
// Description: This alert template detects abnormal measured values using 2 custom
// thresholds and the ability to provide dampening intervals on the thresholds
//
// Threshold for measurement that causes alerts can be set
// in the vars JSON as '<level>_threshold'.
//
// Copyright (c) 2018 by Cisco Systems, Inc.
// All rights reserved.
//-----------------------------------------------------------------------------

//PULSE_RUN_TIME Alert db to store a
var alerts_db string

//PULSE_RUN_TIME InfluxDB Measurement for storing alerts back
var alerts_meas string

//PULSE_RUN_TIME InfluxDB RP for storing alerts back
var alerts_rp string

//PULSE_RUN_TIME Producer name or regex for producer names
var uuid string

//KPI_INTERNAL KPI ID of the kpi this TICKscript measures
var kpi_id = 'device_memory20b1221f_214184464ac0'

//KPI_INTERNAL Alert ID for this KPI Alert event
var alert_id = 'device_memory20b1221f_214184464ac0'

//KPI_INTERNAL Alert message format string
var level2_message = '{{ index .Tags "level" }}: Data: {{ index .Fields "kpi_stream" | printf "%0.2f" }}% has been at a {{ index .Tags "level" }} level for {{ index .Fields "duration" | printf "%0.2f" }} seconds! Threshold: {{ index .Fields "threshold" | printf "%0.2f" }}%.'

//KPI_INTERNAL Alert message format string
var level1_message = '{{ index .Tags "level" }}: Data: {{ index .Fields "kpi_stream" | printf "%0.2f" }}% has been at a {{ index .Tags "level" }} level for {{ index .Fields "duration" | printf "%0.2f" }} seconds! Threshold: {{ index .Fields "threshold" | printf "%0.2f" }}%.'

//KPI_INTERNAL Clear message format string
var clear_message = '{{ index .Tags "level" }}: Data: {{ index .Fields "kpi_stream" | printf "%0.2f" }}% has been normal for {{ index .Fields "duration" | printf "%0.2f" }} seconds. Threshold: {{ index .Fields "threshold" | printf "%0.2f" }}%'

//KPI_INTERNAL Measurement in influxDB to retrieve the data from
var measurement = 'Cisco-IOS-XR-wd-oper:watchdog/nodes/node/memory-state'

//KPI_INTERNAL Optional where filter expression to filter data stream before passing for transformation
var where_filter = lambda: TRUE

// KPI_INTERNAL filter var to filter data only related to producer(s)
var where_producer = lambda: TRUE

//KPI_INTERNAL Optional list of group by dimensions
var groups = [*]

//KPI_INTERNAL Lambda expression to reduce raw data to KPI
var stream_eval_lambda = lambda: float("free-memory")

//KPI_THRESHOLDS (Level 2 Alert Severity) Severity label of a level 2 alert
var level2_severity = 'CRITICAL'

//KPI_THRESHOLDS (Level 2 Alert Threshold) Generates a level 2 alert when this threshold is exceeded
var level2_threshold = 90

//KPI_THRESHOLDS (Level 2 Alert Time) Time that needs to pass after entering the alert state to generate alerts (default 0 seconds)
var level2_time = 0.00

//KPI_THRESHOLDS (Level 1 Alert Severity) Severity label of a level 1 alert
var level1_severity = 'WARNING'

//KPI_THRESHOLDS (Level 1 Alert Threshold) Generates a level 1 alert when this threshold is exceeded
var level1_threshold = 80.00

//KPI_THRESHOLDS (Level 1 Alert Time) Time that needs to pass after entering the alert state to generate alerts (default 0 seconds)
var level1_time = 0.00

//KPI_THRESHOLDS (Clear Time) Time that needs to pass after entering the clear state to generate an INFO alert (default 0 seconds)
var clear_time = 0.00

//KPI_INTERNAL Unit of time for alert alerts
var time_unit = 1s

var data = stream
    |from()
        .measurement(measurement)
        .where(where_producer)
        .where(where_filter)
        .groupBy(groups)
        .quiet()

var transform = data
    |eval(stream_eval_lambda)             //evaluation/reduction of stream data done here
        .as('kpi_stream') //internal field reference
        .quiet()

var level2_branch = transform
    |stateDuration(lambda: "kpi_stream" >= level2_threshold)
        .unit(time_unit)
        .as('duration')
    |default() //insert the thresholds into the data stream
        .tag('kpi_id', kpi_id)
        .tag('level', level2_severity)
        .tag('severity', '2') //2 indicates worst problem
        .field('threshold', level2_threshold)
        .field('alert_src', 'TICK')

var level1_branch = transform
    |stateDuration(lambda: "kpi_stream" < level2_threshold AND "kpi_stream" >= level1_threshold)
        .unit(time_unit)
        .as('duration')
    |default() //insert the thresholds into the data stream
        .tag('kpi_id', kpi_id)
        .tag('level', level1_severity)
        .tag('severity', '1') //1 indicates danger
        .field('threshold', level1_threshold)
        .field('alert_src', 'TICK')

var clear_branch = transform
    |stateDuration(lambda: "kpi_stream" < level1_threshold)
        .unit(time_unit)
        .as('duration')
    |default() //insert the thresholds into the data stream
        .tag('kpi_id', kpi_id)
        .tag('level', 'INFO')
        .tag('severity', '0') //0 indicates safe
        .field('threshold', level1_threshold)
        .field('alert_src', 'TICK')


level2_branch
    |alert()
         // Critical after input time
         .info(lambda: "duration" >= level2_time)
         .stateChangesOnly()
         .id(alert_id)
         .idField('id')
         .message(level2_message)
         .messageField('msg')
         .noRecoveries()
    |influxDBOut()
        .database(alerts_db)
        .retentionPolicy(alerts_rp)
        .measurement(alerts_meas)
        .tag('state', 'alert')

level1_branch
    |alert()
         // Critical after input time
         .info(lambda: "duration" >= level1_time)
         .stateChangesOnly()
         .id(alert_id)
         .idField('id')
         .message(level1_message)
         .messageField('msg')
         .noRecoveries()
    |influxDBOut()
        .database(alerts_db)
        .retentionPolicy(alerts_rp)
        .measurement(alerts_meas)
        .tag('state', 'alert')


clear_branch
    |alert()
        //info on clear after input time
         .info(lambda: "duration" >= clear_time)
         .stateChangesOnly()
         .id(alert_id)
         .idField('id')
         .message(clear_message)
         .messageField('msg')
         .noRecoveries()
    |influxDBOut()
        .database(alerts_db)
        .retentionPolicy(alerts_rp)
        .measurement(alerts_meas)
        .tag('state', 'clear')
